#!/bin/bash

# H = max hash table size for a node and T = log_2(H)
T=27
H=$(echo "2 ^ $T" | bc)

# HS = SHMEM heap size of each process
HS=1000000

# some checks
[ -z "$1" ] && echo "missing \$1 = # of procs per node" && exit 1
[ -z "$OAR_NODEFILE" ] && echo 'not in an OAR job' && exit 1

MAXP=$1
MAXN=$(sort -u $OAR_NODEFILE | wc -l)

helena="helena --algo=dbfs --machine-file=/tmp/machinefile"
helena=$helena" -hs=$HS -C --progress=no-report"
outDir=out/dbfs
mkdir -p $outDir &> /dev/null

models='elevator.5;185008051;22
lifts.9;266445936;22
firewire_link.3;425333983;22
leader_filters.8;431401020;22
collision.5;431965993;22
iprotocol.8;447570146;22
anderson.8;538699029;22
telephony.8;1051746064;24
public_subscribe.5;1153014089;22
lamport.9;1436848880;22
brp.8;1526547707;22
synapse.9;1675298471;22
szymanski.6;6779809484;22'

for N in $(seq $MAXN -1 1)
do
    sort -u $OAR_NODEFILE | head -$N > /tmp/machinefile
    P=$MAXP
    while [ $P -gt 0 ]
    do
	[ $N = 1 -a $P = 1 ] && P=$((P / 2)) && continue
	for l in $models
	do
	    m=$(echo $l | cut -f1 -d';')
	    st=$(echo $l | cut -f2 -d';')
	    cb=$(echo $l | cut -f3 -d';')
	    f=$(scripts/get-file $m dve)
	    [ ! -f $f ] && continue
	    [ $st -gt $((N * H * 80 / 100)) ] && continue
	    p=$P
	    t=$T
	    while [ $p != 1 ]
	    do
		p=$((p / 2))
		t=$((t - 1))
	    done
	    xml=$outDir/$m"_N"$N"_P"$P".xml"
	    [ -f $xml ] && continue
	    cmd=$helena" -t=$t -cb=$cb --report-file=$xml -np=$P $f"
	    echo "***** MODEL=$m - NODES=$N - PROCESSES=$P *****"
	    echo $cmd
	    eval $cmd
	done
        P=$((P / 2))
    done
done

exit 0
